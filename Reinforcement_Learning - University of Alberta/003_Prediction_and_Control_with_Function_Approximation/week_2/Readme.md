**Lesson 1: Feature Construction for Linear Methods** 

- Describe the difference between coarse coding and tabular representations 
- Explain the trade-off when designing representations between discrimination and generalization 
- Understand how different coarse coding schemes affect the functions that can be represented 
- Explain how tile coding is a (computationally?) convenient case of coarse coding 
- Describe how designing the tilings affects the resultant representation 
- Understand that tile coding is a computationally efficient implementation of coarse coding 

**Lesson 2: Neural Networks**
- Define a neural network
- Define activation functions
- Define a feedforward architecture 
- Understand how neural networks are doing feature construction 
- Understand how neural networks are a non-linear function of state 
- Understand how deep networks are a composition of layers 
- Understand the tradeoff between learning capacity and challenges presented by deeper networks 

**Lesson 3: Training Neural Networks**
- Compute the gradient of a single hidden layer neural network 
- Understand how to compute the gradient for arbitrarily deep networks 
- Understand the importance of initialization for neural networks 
- Describe strategies for initializing neural networks 
- Describe optimization techniques for training neural networks

**Programming Assignment: Semi-gradient TD with a Neural Network** (https://github.com/bhunkeler/DataScienceCoursera/tree/master/Reinforcement_Learning%20-%20University%20of%20Alberta/003_Prediction_and_Control_with_Function_Approximation/week_2/assignment)
